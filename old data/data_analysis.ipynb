{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the data:\n",
      "                   Company Name     Equity     Ticker Symbol  Ticker    E  \\\n",
      "0                   Hanwha Corp  KS Equity  000880 KS Equity  000880  0.4   \n",
      "1    Mitsubishi Shokuhin Co Ltd  JP Equity    7451 JP Equity    7451  1.1   \n",
      "2                   Doosan Corp  KS Equity  000150 KS Equity  000150  1.6   \n",
      "3            SK Networks Co Ltd  KS Equity  001740 KS Equity  001740  0.4   \n",
      "4  Cosmo Energy Holdings Co Ltd  JP Equity    5021 JP Equity    5021  2.7   \n",
      "\n",
      "     S    G       ESG         EPS  Profit Margin   Tobin's Q  Return on Asset  \\\n",
      "0  0.4  2.5  1.100000  863.333332        0.611193   0.990838         0.288494   \n",
      "1  1.2  2.3  1.533333   50.486667        0.445298   1.024237         1.652530   \n",
      "2  3.0  2.3  2.300000  -17.603234        0.012043   0.980031         0.003339   \n",
      "3  0.3  2.1  0.933333   50.811210        0.622182   0.900873        -0.078783   \n",
      "4  2.7  3.3  2.900000  270.068667        3.456660   1.044745         4.664905   \n",
      "\n",
      "   Return on Equity  Debt To Market Cap Ratio  Total Asset Turnover  \\\n",
      "0          9.721551                  4.779814              0.312051   \n",
      "1          7.170111                  0.044665              3.581568   \n",
      "2         -0.048393                  5.547358              0.609290   \n",
      "3         -0.241107                  1.488726              1.836434   \n",
      "4         43.710127                  3.115284              1.553640   \n",
      "\n",
      "   Price to Sales Ratio  \n",
      "0              0.060035  \n",
      "1              0.073696  \n",
      "2              0.101855  \n",
      "3              0.102239  \n",
      "4              0.112339  \n",
      "\n",
      "Shape of the dataframe: (1963, 16)\n",
      "\n",
      "Data types of columns:\n",
      "Company Name                 object\n",
      "Equity                       object\n",
      "Ticker Symbol                object\n",
      "Ticker                       object\n",
      "E                           float64\n",
      "S                           float64\n",
      "G                           float64\n",
      "ESG                         float64\n",
      "EPS                         float64\n",
      "Profit Margin               float64\n",
      "Tobin's Q                   float64\n",
      "Return on Asset             float64\n",
      "Return on Equity            float64\n",
      "Debt To Market Cap Ratio    float64\n",
      "Total Asset Turnover        float64\n",
      "Price to Sales Ratio        float64\n",
      "dtype: object\n",
      "\n",
      "Basic statistics:\n",
      "                 E            S            G          ESG           EPS  \\\n",
      "count  1926.000000  1926.000000  1926.000000  1926.000000   1926.000000   \n",
      "mean      2.457165     2.277310     3.227259     2.653911    185.747874   \n",
      "std       1.435342     1.200255     0.926162     0.991618   1734.459278   \n",
      "min       0.000000     0.000000     0.000000     0.033333  -3131.513415   \n",
      "25%       1.000000     1.300000     2.600000     1.900000      0.356667   \n",
      "50%       2.500000     2.300000     3.300000     2.666667      1.278333   \n",
      "75%       3.500000     3.200000     4.000000     3.433333     21.008500   \n",
      "max       5.000000     5.000000     5.000000     5.000000  55299.225297   \n",
      "\n",
      "       Profit Margin     Tobin's Q  Return on Asset  Return on Equity  \\\n",
      "count     1926.000000  1926.000000      1926.000000       1926.000000   \n",
      "mean        28.248941     1.909164         5.620833         17.094903   \n",
      "std        465.649661     2.148117         8.408765         46.959964   \n",
      "min       -165.394348     0.576133       -29.338186        -84.337769   \n",
      "25%          3.768584     1.049967         1.886927          7.075077   \n",
      "50%          8.239839     1.395937         4.532202         11.767946   \n",
      "75%         16.762520     2.068347         7.810940         18.610699   \n",
      "max      19779.899637    59.203895       217.886548       1142.485629   \n",
      "\n",
      "       Debt To Market Cap Ratio  Total Asset Turnover  Price to Sales Ratio  \n",
      "count               1926.000000           1926.000000           1926.000000  \n",
      "mean                   0.678082              0.694608              7.890253  \n",
      "std                    1.522108              0.574564            198.952887  \n",
      "min                    0.000000              0.001132              0.060035  \n",
      "25%                    0.103508              0.282422              0.867794  \n",
      "50%                    0.258402              0.599572              1.742512  \n",
      "75%                    0.596114              0.936627              3.348298  \n",
      "max                   30.760378              4.414300           8683.387800  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Read the Excel file\n",
    "# You can change the filename to either:\n",
    "# 'GR Historical Combined.xlsx' or 'ESG Data With Company Performance.xlsx'\n",
    "file_name = 'ESG Data With Company Performance.xlsx'\n",
    "df = pd.read_excel(file_name, sheet_name=0)  # Explicitly specify the engine\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(\"First few rows of the data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display basic information about the dataframe\n",
    "print(\"\\nShape of the dataframe:\", df.shape)\n",
    "print(\"\\nData types of columns:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 564 US equities\n",
      "Successfully exported US ticker symbols to us_ticker_symbols.csv\n"
     ]
    }
   ],
   "source": [
    " #Filter for US equities\n",
    "us_equities = df[df['Equity'].str.contains('US Equity', na=False)]\n",
    "\n",
    "# Export US equities to CSV\n",
    "us_equities[['Company Name', 'Ticker']].to_csv('us_ticker_symbols.csv', index=False)\n",
    "print(f\"Found {len(us_equities)} US equities\")\n",
    "print(f\"Successfully exported US ticker symbols to us_ticker_symbols.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABC', 'MCK', 'KR', 'BG', 'AN', 'BBBY', 'JBL', 'ARW', 'AVT', 'F', 'M', 'FLR', 'FLEX', 'CNC', 'MAN', 'ADNT', 'ADM', 'CVS', 'ESRX', 'GM', 'VLO', 'ANDV', 'BBY', 'KSS', 'MPC', 'GT', 'TGT', 'JWN', 'WMT', 'UAL', 'PDCO', 'SYY', 'SIG', 'AAL', 'WHR', 'PSX', 'XRX', 'HFC', 'COST', 'AES', 'LEA', 'WFT', 'CPN', 'WBA', 'CTL', 'NCR', 'ANTM', 'ARMK', 'TSN', 'JEC', 'HUM', 'FL', 'NAVI', 'CDW', 'KMX', 'GPS', 'AA', 'S', 'PRU', 'CHRW', 'ALV', 'MNK', 'AIZ', 'GPC', 'ARNC', 'AAP', 'HPE', 'MET', 'ORI', 'NRG', 'SC', 'ALL', 'VOYA', 'VIAB', 'DAL', 'DVA', 'AET', 'CBRE', 'UNM', 'DXC', 'NUE', 'FDX', 'DLTR', 'BMS', 'WRK', 'DG', 'IP', 'UHS', 'XL', 'HSIC', 'UNH', 'AXS', 'LOW', 'NWSA', 'PHM', 'LEN', 'CSRA', 'TXT', 'FE', 'NWS', 'IPG', 'MAT', 'BWA', 'EXC', 'NWL', 'TRGP', 'HIG', 'AIG', 'DHI', 'OMC', 'CI', 'WRB', 'ALK', 'LNC', 'TSCO', 'JCI', 'LKQ', 'MOS', 'TOL', 'PGR', 'DISCK', 'MDU', 'ALLY', 'HBI', 'L', 'FNF', 'LYB', 'PVH', 'STX', 'TMUS', 'TRV', 'BLL', 'WDC', 'CNP', 'ETR', 'ASH', 'RHI', 'GWW', 'RL', 'OKE', 'GE', 'PFG', 'PII', 'CMI', 'T', 'TGNA', 'FCX', 'Y', 'DVN', 'TJX', 'HOG', 'AVY', 'CNA', 'COTY', 'EPC', 'DRI', 'EMN', 'XOM', 'LLL', 'DISH', 'SCG', 'HLF', 'CCE', 'RE', 'FLS', 'COF', 'UAA', 'DE', 'PCG', 'DTE', 'UPS', 'APTV', 'DOV', 'AFL', 'INGR', 'VZ', 'LEG', 'IR', 'SRCL', 'WLK', 'LUV', 'LH', 'SYF', 'UTX', 'TAP', 'EXPD', 'AER', 'WU', 'CBS', 'ADS', 'NI', 'RRC', 'PKG', 'ETN', 'MYL', 'PNR', 'JBHT', 'CPB', 'MGM', 'K', 'IBM', 'CVX', 'SJM', 'NVR', 'PH', 'SWK', 'LMT', 'AJG', 'DGX', 'FBHS', 'EIX', 'AR', 'AYI', 'SEE', 'NOV', 'RJF', 'GIS', 'KORS', 'BA', 'AMP', 'EXPE', 'HRL', 'PPG', 'MHK', 'LBTYK', 'NLSN', 'CMS', 'BRK/A', 'DST', 'URI', 'JNPR', 'ROST', 'GD', 'DWDP', 'YUMC', 'LBTYA', 'HAL', 'SO', 'CB', 'ED', 'CMCSA', 'XEL', 'NOC', 'HD', 'WAB', 'MS', 'CHTR', 'HPT', 'FOX', 'MAR', 'MU', 'FOXA', 'CINF', 'CMG', 'KMB', 'C', 'AEP', 'IQV', 'CF', 'ACGL', 'RSG', 'RTN', 'HAS', 'AEE', 'SNA', 'GS', 'DFS', 'AXP', 'NUAN', 'COP', 'ORLY', 'NCLH', 'TMK', 'VFC', 'MUR', 'PRGO', 'ACN', 'CE', 'TWX', 'DUK', 'TEL', 'MDLZ', 'ES', 'DOX', 'SHW', 'ULTA', 'WM', 'PEP', 'IRM', 'CIT', 'SRE', 'AGR', 'MKL', 'TPR', 'WLTW', 'PNW', 'BR', 'KEYS', 'WEC', 'LSXMK', 'LSXMA', 'APC', 'XYL', 'HST', 'NTAP', 'IVZ', 'GLW', 'MKC', 'RNR', 'PEG', 'CCL', 'EMR', 'WYNN', 'APA', 'NEM', 'COL', 'HON', 'CTAS', 'LNT', 'CLX', 'WFC', 'HLT', 'FITB', 'ECL', 'HRS', 'BAC', 'DIS', 'HES', 'HSY', 'WMB', 'KMI', 'RCL', 'NKE', 'TSS', 'MMC', 'ZBH', 'PPL', 'KEY', 'CTSH', 'TIF', 'MRO', 'SLB', 'SNI', 'NFX', 'CFG', 'STT', 'STI', 'QRVO', 'JPM', 'IAC', 'ALLE', 'NBL', 'LRCX', 'CHD', 'XRAY', 'IFF', 'FAST', 'PG', 'HBAN', 'BBT', 'NLY', 'RF', 'BK', 'KHC', 'INTC', 'MLM', 'GNTX', 'BAX', 'HP', 'NYCB', 'IT', 'BEN', 'FIS', 'GRMN', 'AMZN', 'SBUX', 'HOLX', 'DHR', 'MON', 'EQT', 'ROK', 'AON', 'ABT', 'PBCT', 'BRO', 'SYMC', 'AMAT', 'ITW', 'TRMB', 'WY', 'GILD', 'USB', 'EL', 'ZION', 'AAPL', 'PX', 'D', 'TRIP', 'MDT', 'NSC', 'VAR', 'APH', 'FTV', 'TMO', 'QCOM', 'LLY', 'PNC', 'AME', 'BDX', 'CSCO', 'NTRS', 'AGNC', 'AGN', 'MRK', 'PFE', 'ADP', 'FMC', 'APD', 'NXPI', 'MMM', 'LULU', 'GPN', 'CERN', 'VMC', 'FFIV', 'NEE', 'MRVL', 'AKAM', 'ALB', 'EBAY', 'BSX', 'LVS', 'EFX', 'OXY', 'MTB', 'KSU', 'KLAC', 'AMG', 'AWK', 'CSX', 'SNPS', 'CMA', 'A', 'JNJ', 'SYK', 'TSLA', 'BMY', 'UNP', 'CBSH', 'CTXS', 'PXD', 'SWKS', 'ORCL', 'TROW', 'FRC', 'COO', 'KO', 'BIIB', 'WELL', 'XEC', 'MCHP', 'ABBV', 'EOG', 'NDAQ', 'SCCO', 'VER', 'FISV', 'JAZZ', 'STZ', 'AMGN', 'ETFC', 'RMD', 'MTD', 'VTR', 'ROP', 'ADI', 'KIM', 'BCR', 'CLR', 'VNO', 'MO', 'HCP', 'BLK', 'MXIM', 'SLG', 'CELG', 'MSFT', 'TXN', 'GOOGL', 'VMW', 'WRI', 'WAT', 'PYPL', 'ZTS', 'SEIC', 'XLNX', 'COG', 'PAYX', 'AMTD', 'ATVI', 'YNDX', 'MAA', 'REGN', 'EA', 'BXP', 'CLB', 'VRSK', 'SCHW', 'SPGI', 'BF/B', 'FLT', 'TWTR', 'CRM', 'CXO', 'PANW', 'EQIX', 'INTU', 'EW', 'DLR', 'ALXN', 'GGP', 'MAC', 'RHT', 'LPT', 'CBOE', 'ICE', 'SPG', 'ALKS', 'AMT', 'CCI', 'NFLX', 'CHKP', 'EQR', 'EXR', 'SPLK', 'UDR', 'ARE', 'REG', 'MNST', 'ANET', 'FRT', 'AVB', 'WDAY', 'ANSS', 'BMRN', 'ESS', 'O', 'ILMN', 'PLD', 'DRE', 'NOW', 'ADBE', 'ADSK', 'V', 'FB', 'NVDA', 'PSA', 'ALGN', 'INCY', 'CME', 'MA', 'ISRG', 'VRTX', 'LBRDA']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('us_ticker_symbols.csv')\n",
    "df.head()\n",
    "tickers = df['Ticker'].tolist()\n",
    "\n",
    "print(tickers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC\n",
      "yfinance.Ticker object <ABC>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['ABC']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "\n",
      "1 Failed download:\n",
      "['ABC']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "\n",
      "1 Failed download:\n",
      "['ABC']: YFTzMissingError('possibly delisted; no timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCK\n",
      "yfinance.Ticker object <MCK>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Adj Close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/MLHW/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Adj Close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 28\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(stock)\n\u001b[1;32m     23\u001b[0m     info \u001b[38;5;241m=\u001b[39m stock\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m     25\u001b[0m     market_performance \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m: ticker,\n\u001b[1;32m     27\u001b[0m        \n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5Y_Change (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mget_percent_change\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiods\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m5Y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoday\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10Y_Change (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m: get_percent_change(ticker, periods[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10Y\u001b[39m\u001b[38;5;124m'\u001b[39m], today),\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYTD_Change (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m: get_percent_change(ticker, periods[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYTD\u001b[39m\u001b[38;5;124m'\u001b[39m], today),\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Revenue\u001b[39m\u001b[38;5;124m'\u001b[39m: info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotalRevenue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGross Profit\u001b[39m\u001b[38;5;124m'\u001b[39m: info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrossProfits\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperating Income\u001b[39m\u001b[38;5;124m'\u001b[39m: info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moperatingIncome\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNet Income\u001b[39m\u001b[38;5;124m'\u001b[39m: info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetIncomeToCommon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPS\u001b[39m\u001b[38;5;124m'\u001b[39m: info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrailingEps\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m     }\n\u001b[1;32m     38\u001b[0m     financial_data\u001b[38;5;241m.\u001b[39mappend(market_performance)\n\u001b[1;32m     40\u001b[0m financial_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(financial_data)\n",
      "Cell \u001b[0;32mIn[24], line 11\u001b[0m, in \u001b[0;36mget_percent_change\u001b[0;34m(ticker, start_date, end_date)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_percent_change\u001b[39m(ticker, start_date, end_date):\n\u001b[0;32m---> 11\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43myf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAdj Close\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/MLHW/lib/python3.11/site-packages/pandas/core/frame.py:4101\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[1;32m   4100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 4101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_multilevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4102\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "File \u001b[0;32m~/anaconda3/envs/MLHW/lib/python3.11/site-packages/pandas/core/frame.py:4159\u001b[0m, in \u001b[0;36mDataFrame._getitem_multilevel\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_getitem_multilevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   4158\u001b[0m     \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n\u001b[0;32m-> 4159\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, (\u001b[38;5;28mslice\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m   4161\u001b[0m         new_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[loc]\n",
      "File \u001b[0;32m~/anaconda3/envs/MLHW/lib/python3.11/site-packages/pandas/core/indexes/multi.py:3040\u001b[0m, in \u001b[0;36mMultiIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n\u001b[1;32m   3039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m-> 3040\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_level_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _maybe_to_slice(loc)\n\u001b[1;32m   3043\u001b[0m keylen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(key)\n",
      "File \u001b[0;32m~/anaconda3/envs/MLHW/lib/python3.11/site-packages/pandas/core/indexes/multi.py:3391\u001b[0m, in \u001b[0;36mMultiIndex._get_level_indexer\u001b[0;34m(self, key, level, indexer)\u001b[0m\n\u001b[1;32m   3388\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(i, j, step)\n\u001b[1;32m   3390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3391\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_loc_single_level_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lexsort_depth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3394\u001b[0m         \u001b[38;5;66;03m# Desired level is not sorted\u001b[39;00m\n\u001b[1;32m   3395\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   3396\u001b[0m             \u001b[38;5;66;03m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/MLHW/lib/python3.11/site-packages/pandas/core/indexes/multi.py:2980\u001b[0m, in \u001b[0;36mMultiIndex._get_loc_single_level_index\u001b[0;34m(self, level_index, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2979\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlevel_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MLHW/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Adj Close'"
     ]
    }
   ],
   "source": [
    "today = datetime.now()\n",
    "periods = {\n",
    "\n",
    "    \n",
    "    '5Y': today - timedelta(days=5*365),\n",
    "    '10Y': today - timedelta(days=10*365),\n",
    "    'YTD': datetime(today.year, 1, 1)\n",
    "}\n",
    "\n",
    "def get_percent_change(ticker, start_date, end_date):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, progress=False)['Adj Close']\n",
    "    if len(data) < 2:\n",
    "        return None\n",
    "    return ((data[-1] - data[0]) / data[0]) * 100\n",
    "\n",
    "financial_data = []\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(ticker)\n",
    "    stock = yf.Ticker(ticker)\n",
    "    print(stock)\n",
    "    info = stock.info\n",
    "    \n",
    "    market_performance = {\n",
    "        'Ticker': ticker,\n",
    "       \n",
    "        '5Y_Change (%)': get_percent_change(ticker, periods['5Y'], today),\n",
    "        '10Y_Change (%)': get_percent_change(ticker, periods['10Y'], today),\n",
    "        'YTD_Change (%)': get_percent_change(ticker, periods['YTD'], today),\n",
    "        'Total Revenue': info.get('totalRevenue', None),\n",
    "        'Gross Profit': info.get('grossProfits', None),\n",
    "        'Operating Income': info.get('operatingIncome', None),\n",
    "        'Net Income': info.get('netIncomeToCommon', None),\n",
    "        'EPS': info.get('trailingEps', None)\n",
    "    }\n",
    "    \n",
    "    financial_data.append(market_performance)\n",
    "\n",
    "financial_df = pd.DataFrame(financial_data)\n",
    "\n",
    "# Save the data to CSV for easy access\n",
    "financial_df.to_csv('financial_market_data.csv', index=False)\n",
    "\n",
    "print(financial_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import requests\n",
    "ALPHA_VANTAGE_API_KEY = \"0I2PKBXXPOKNBHL6\"  # Replace with your actual API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time periods\n",
    "today = datetime.now()\n",
    "periods = {\n",
    "    '6M': today - timedelta(days=182),\n",
    "    '1Y': today - timedelta(days=365),\n",
    "    '3Y': today - timedelta(days=3*365),\n",
    "    '5Y': today - timedelta(days=5*365),\n",
    "    '10Y': today - timedelta(days=10*365),\n",
    "    'YTD': datetime(today.year, 1, 1)\n",
    "}\n",
    "\n",
    "def get_alpha_vantage_time_series(ticker, outputsize=\"full\"):\n",
    "    \"\"\"\n",
    "    Fetch historical time series data from Alpha Vantage\n",
    "    outputsize can be 'compact' (latest 100 data points) or 'full' (up to 20 years)\n",
    "    \"\"\"\n",
    "    url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={ticker}&outputsize={outputsize}&apikey={ALPHA_VANTAGE_API_KEY}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        \n",
    "        if \"Error Message\" in data:\n",
    "            print(f\"Error for {ticker}: {data['Error Message']}\")\n",
    "            return None\n",
    "        \n",
    "        if \"Time Series (Daily)\" not in data:\n",
    "            print(f\"No time series data found for {ticker}\")\n",
    "            return None\n",
    "            \n",
    "        # Convert to DataFrame\n",
    "        time_series = data[\"Time Series (Daily)\"]\n",
    "        df = pd.DataFrame.from_dict(time_series, orient='index')\n",
    "        \n",
    "        # Convert string values to float\n",
    "        for col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "            \n",
    "        # Rename columns to more friendly names\n",
    "        df.rename(columns={\n",
    "            '1. open': 'Open',\n",
    "            '2. high': 'High',\n",
    "            '3. low': 'Low',\n",
    "            '4. close': 'Close',\n",
    "            '5. adjusted close': 'Adj Close',\n",
    "            '6. volume': 'Volume',\n",
    "            '7. dividend amount': 'Dividend',\n",
    "            '8. split coefficient': 'Split'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        # Sort by date (ascending)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df.sort_index(inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving time series data for {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_alpha_vantage_company_overview(ticker):\n",
    "    \"\"\"Fetch company overview data from Alpha Vantage\"\"\"\n",
    "    url = f\"https://www.alphavantage.co/query?function=OVERVIEW&symbol={ticker}&apikey={ALPHA_VANTAGE_API_KEY}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        \n",
    "        if not data or \"Symbol\" not in data:\n",
    "            print(f\"No overview data found for {ticker}\")\n",
    "            return None\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving company overview for {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_alpha_vantage_income_statement(ticker):\n",
    "    \"\"\"Fetch income statement data from Alpha Vantage\"\"\"\n",
    "    url = f\"https://www.alphavantage.co/query?function=INCOME_STATEMENT&symbol={ticker}&apikey={ALPHA_VANTAGE_API_KEY}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        \n",
    "        if not data or \"annualReports\" not in data or not data[\"annualReports\"]:\n",
    "            print(f\"No income statement data found for {ticker}\")\n",
    "            return None\n",
    "            \n",
    "        # Get the most recent annual report\n",
    "        return data[\"annualReports\"][0]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving income statement for {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_percent_change(time_series_data, start_date, end_date):\n",
    "    \"\"\"Calculate percentage change in stock price between two dates.\"\"\"\n",
    "    if time_series_data is None or time_series_data.empty:\n",
    "        return None\n",
    "        \n",
    "    # Filter data for the date range\n",
    "    mask = (time_series_data.index >= start_date) & (time_series_data.index <= end_date)\n",
    "    filtered_data = time_series_data.loc[mask]\n",
    "    \n",
    "    if len(filtered_data) < 2:\n",
    "        return None\n",
    "        \n",
    "    # Calculate percentage change\n",
    "    start_price = filtered_data['Adj Close'].iloc[0]\n",
    "    end_price = filtered_data['Adj Close'].iloc[-1]\n",
    "    return ((end_price - start_price) / start_price) * 100\n",
    "\n",
    "def get_financial_data(tickers):\n",
    "    \"\"\"Get financial data for a list of tickers using Alpha Vantage.\"\"\"\n",
    "    financial_data = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers):\n",
    "        print(f\"Processing {ticker} ({i+1}/{len(tickers)})\")\n",
    "        \n",
    "        try:\n",
    "            # Get time series data\n",
    "            time_series = get_alpha_vantage_time_series(ticker)\n",
    "            \n",
    "            # Get company overview\n",
    "            overview = get_alpha_vantage_company_overview(ticker)\n",
    "            \n",
    "            # Get income statement\n",
    "            income_stmt = get_alpha_vantage_income_statement(ticker)\n",
    "            \n",
    "            # If we couldn't get any data, skip this ticker\n",
    "            if time_series is None and overview is None and income_stmt is None:\n",
    "                print(f\"Could not retrieve any data for {ticker}, skipping...\")\n",
    "                continue\n",
    "                \n",
    "            # Calculate price changes\n",
    "            market_performance = {\n",
    "                'Ticker': ticker,\n",
    "                '6M_Change (%)': get_percent_change(time_series, periods['6M'], today) if time_series is not None else None,\n",
    "                '1Y_Change (%)': get_percent_change(time_series, periods['1Y'], today) if time_series is not None else None,\n",
    "                '3Y_Change (%)': get_percent_change(time_series, periods['3Y'], today) if time_series is not None else None,\n",
    "                '5Y_Change (%)': get_percent_change(time_series, periods['5Y'], today) if time_series is not None else None,\n",
    "                '10Y_Change (%)': get_percent_change(time_series, periods['10Y'], today) if time_series is not None else None,\n",
    "                'YTD_Change (%)': get_percent_change(time_series, periods['YTD'], today) if time_series is not None else None,\n",
    "            }\n",
    "            \n",
    "            # Get financial metrics\n",
    "            # Try to get from overview first, then from income statement\n",
    "            financial_metrics = {\n",
    "                'Total Revenue': None,\n",
    "                'Gross Profit': None,\n",
    "                'Operating Income': None,\n",
    "                'Net Income': None,\n",
    "                'EPS': None\n",
    "            }\n",
    "            \n",
    "            # Extract from overview\n",
    "            if overview is not None:\n",
    "                financial_metrics['Total Revenue'] = float(overview.get('RevenueTTM', 0)) if overview.get('RevenueTTM') else None\n",
    "                financial_metrics['EPS'] = float(overview.get('EPS', 0)) if overview.get('EPS') else None\n",
    "            \n",
    "            # Extract from income statement\n",
    "            if income_stmt is not None:\n",
    "                if financial_metrics['Total Revenue'] is None:\n",
    "                    financial_metrics['Total Revenue'] = float(income_stmt.get('totalRevenue', 0)) if income_stmt.get('totalRevenue') else None\n",
    "                \n",
    "                financial_metrics['Gross Profit'] = float(income_stmt.get('grossProfit', 0)) if income_stmt.get('grossProfit') else None\n",
    "                financial_metrics['Operating Income'] = float(income_stmt.get('operatingIncome', 0)) if income_stmt.get('operatingIncome') else None\n",
    "                financial_metrics['Net Income'] = float(income_stmt.get('netIncome', 0)) if income_stmt.get('netIncome') else None\n",
    "                \n",
    "                if financial_metrics['EPS'] is None:\n",
    "                    financial_metrics['EPS'] = float(income_stmt.get('reportedEPS', 0)) if income_stmt.get('reportedEPS') else None\n",
    "            \n",
    "            # Combine all data\n",
    "            market_performance.update(financial_metrics)\n",
    "            financial_data.append(market_performance)\n",
    "            \n",
    "            # Add a delay to avoid hitting Alpha Vantage API rate limits\n",
    "            # Free tier is limited to 5 calls per minute and 500 calls per day\n",
    "            time.sleep(12)  # Sleep for 12 seconds to stay within the 5 calls per minute limit\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ticker}: {e}\")\n",
    "    \n",
    "    return financial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ABC (1/564)\n",
      "Could not find CIK for ABC\n",
      "Failed to get data for ABC YTD\n",
      "Failed to get data for ABC 1Y\n",
      "Failed to get data for ABC 5Y\n",
      "Failed to get data for ABC 10Y\n",
      "Processing MCK (2/564)\n",
      "Could not find CIK for MCK\n",
      "Failed to get data for MCK YTD\n",
      "Failed to get data for MCK 1Y\n",
      "Failed to get data for MCK 5Y\n",
      "Failed to get data for MCK 10Y\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_tickers_free\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinancial_data_free.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[19], line 109\u001b[0m, in \u001b[0;36mprocess_tickers_free\u001b[0;34m(tickers)\u001b[0m\n\u001b[1;32m    106\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(ticker_data)\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# Add delay to avoid overwhelming the servers\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import re\n",
    "\n",
    "def get_sec_filings(ticker, filing_type=\"10-K\", count=1):\n",
    "    \"\"\"Get the URLs of recent SEC filings for a company\"\"\"\n",
    "    try:\n",
    "        # Get the CIK number for the company\n",
    "        url = f\"https://www.sec.gov/cgi-bin/browse-edgar?CIK={ticker}&owner=exclude&action=getcompany&Find=Search\"\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        cik_match = re.search(r'CIK=(\\d+)', response.text)\n",
    "        if not cik_match:\n",
    "            print(f\"Could not find CIK for {ticker}\")\n",
    "            return None\n",
    "        \n",
    "        cik = cik_match.group(1)\n",
    "        \n",
    "        # Get the filings\n",
    "        url = f\"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={cik}&type={filing_type}&count={count}\"\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        \n",
    "        # Extract links to the filings\n",
    "        document_urls = re.findall(r'<a href=\"(/Archives/edgar/data/[^\"]+)\"', response.text)\n",
    "        if not document_urls:\n",
    "            print(f\"No {filing_type} filings found for {ticker}\")\n",
    "            return None\n",
    "        \n",
    "        # Return the first filing URL\n",
    "        return f\"https://www.sec.gov{document_urls[0]}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving SEC filings for {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_yahoo_price_history(ticker):\n",
    "    \"\"\"Get historical prices from Yahoo Finance using requests\"\"\"\n",
    "    try:\n",
    "        # Calculate time periods\n",
    "        today = datetime.now()\n",
    "        periods = {\n",
    "            'YTD': datetime(today.year, 1, 1),\n",
    "            '1Y': today - timedelta(days=365),\n",
    "            '5Y': today - timedelta(days=5*365),\n",
    "            '10Y': today - timedelta(days=10*365)\n",
    "        }\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for period_name, start_date in periods.items():\n",
    "            # Convert dates to UNIX timestamps\n",
    "            period1 = int(start_date.timestamp())\n",
    "            period2 = int(today.timestamp())\n",
    "            \n",
    "            # Make the request to Yahoo Finance\n",
    "            url = f\"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={period1}&period2={period2}&interval=1d&events=history\"\n",
    "            response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"Failed to get data for {ticker} {period_name}\")\n",
    "                results[period_name] = None\n",
    "                continue\n",
    "                \n",
    "            # Parse the CSV data\n",
    "            lines = response.text.strip().split('\\n')\n",
    "            if len(lines) < 2:\n",
    "                results[period_name] = None\n",
    "                continue\n",
    "                \n",
    "            # Skip header, get first and last rows\n",
    "            first_row = lines[1].split(',')\n",
    "            last_row = lines[-1].split(',')\n",
    "            \n",
    "            # Calculate percent change\n",
    "            try:\n",
    "                first_price = float(first_row[5])  # Adj Close\n",
    "                last_price = float(last_row[5])  # Adj Close\n",
    "                change_pct = ((last_price - first_price) / first_price) * 100\n",
    "                results[f'{period_name}_Change (%)'] = change_pct\n",
    "            except (ValueError, IndexError):\n",
    "                results[f'{period_name}_Change (%)'] = None\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving price history for {ticker}: {e}\")\n",
    "        return {}\n",
    "\n",
    "def process_tickers_free(tickers):\n",
    "    \"\"\"Process tickers using free data sources\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers):\n",
    "        print(f\"Processing {ticker} ({i+1}/{len(tickers)})\")\n",
    "        \n",
    "        ticker_data = {'Ticker': ticker}\n",
    "        \n",
    "        # Get SEC filing URL (just to show it's available)\n",
    "        filing_url = get_sec_filings(ticker)\n",
    "        if filing_url:\n",
    "            ticker_data['Latest 10-K URL'] = filing_url\n",
    "        \n",
    "        # Get price history from Yahoo Finance (alternate method)\n",
    "        price_data = get_yahoo_price_history(ticker)\n",
    "        ticker_data.update(price_data)\n",
    "        \n",
    "        results.append(ticker_data)\n",
    "        \n",
    "        # Add delay to avoid overwhelming the servers\n",
    "        time.sleep(3)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage\n",
    "df = process_tickers_free(tickers)\n",
    "df.to_csv('financial_data_free.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLHW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
