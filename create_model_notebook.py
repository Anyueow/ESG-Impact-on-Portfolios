import json
import os

def create_notebook():
    notebook = {
        "cells": [
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "# ESG Portfolio Modeling Analysis\n",
                    "\n",
                    "This notebook implements various modeling strategies to analyze the relationship between ESG scores and stock performance.\n",
                    "\n",
                    "**Business Question:** Can a long-short portfolio strategy based on ESG score rankings within the S&P 500 consistently generate excess returns, and should fund managers consider ESG scores as a signal for portfolio construction?"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "import pandas as pd\n",
                    "import numpy as np\n",
                    "import matplotlib.pyplot as plt\n",
                    "import seaborn as sns\n",
                    "from sklearn.linear_model import LinearRegression\n",
                    "from sklearn.ensemble import RandomForestRegressor\n",
                    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
                    "from sklearn.compose import ColumnTransformer\n",
                    "from sklearn.pipeline import Pipeline\n",
                    "from sklearn.metrics import r2_score, mean_squared_error\n",
                    "from sklearn.model_selection import train_test_split\n",
                    "import xgboost as xgb\n",
                    "from sklearn.cluster import KMeans\n",
                    "import plotly.express as px\n",
                    "import plotly.graph_objects as go\n",
                    "from plotly.subplots import make_subplots\n",
                    "\n",
                    "# Set style\n",
                    "plt.style.use('seaborn')\n",
                    "sns.set_palette('husl')"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "# Read the data\n",
                    "df = pd.read_csv('merged_data.csv')\n",
                    "print(f\"Dataset shape: {df.shape}\")\n",
                    "df.head()"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 1. Regression Analysis\n",
                    "\n",
                    "We'll use multiple regression models to analyze the relationship between ESG scores and returns, controlling for sector effects."
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "def prepare_regression_data(df, target_col='12M_Return'):\n",
                    "    \"\"\"Prepare data for regression analysis\"\"\"\n",
                    "    # Features for regression\n",
                    "    X = df[['totalEsg', 'GIS Sector']]\n",
                    "    y = df[target_col]\n",
                    "    \n",
                    "    # Create preprocessing pipeline\n",
                    "    preprocessor = ColumnTransformer(\n",
                    "        transformers=[\n",
                    "            ('num', StandardScaler(), ['totalEsg']),\n",
                    "            ('cat', OneHotEncoder(drop='first', sparse_output=False), ['GIS Sector'])\n",
                    "        ])\n",
                    "    \n",
                    "    return train_test_split(X, y, test_size=0.2, random_state=42), preprocessor\n",
                    "\n",
                    "# Prepare data\n",
                    "(X_train, X_test, y_train, y_test), preprocessor = prepare_regression_data(df)\n",
                    "\n",
                    "# Linear Regression\n",
                    "lr_pipeline = Pipeline([\n",
                    "    ('preprocessor', preprocessor),\n",
                    "    ('regressor', LinearRegression())\n",
                    "])\n",
                    "\n",
                    "lr_pipeline.fit(X_train, y_train)\n",
                    "lr_pred = lr_pipeline.predict(X_test)\n",
                    "\n",
                    "# Random Forest\n",
                    "rf_pipeline = Pipeline([\n",
                    "    ('preprocessor', preprocessor),\n",
                    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
                    "])\n",
                    "\n",
                    "rf_pipeline.fit(X_train, y_train)\n",
                    "rf_pred = rf_pipeline.predict(X_test)\n",
                    "\n",
                    "# XGBoost\n",
                    "xgb_pipeline = Pipeline([\n",
                    "    ('preprocessor', preprocessor),\n",
                    "    ('regressor', xgb.XGBRegressor(objective='reg:squarederror', random_state=42))\n",
                    "])\n",
                    "\n",
                    "xgb_pipeline.fit(X_train, y_train)\n",
                    "xgb_pred = xgb_pipeline.predict(X_test)\n",
                    "\n",
                    "# Compare results\n",
                    "results = pd.DataFrame({\n",
                    "    'Model': ['Linear Regression', 'Random Forest', 'XGBoost'],\n",
                    "    'R2 Score': [\n",
                    "        r2_score(y_test, lr_pred),\n",
                    "        r2_score(y_test, rf_pred),\n",
                    "        r2_score(y_test, xgb_pred)\n",
                    "    ],\n",
                    "    'RMSE': [\n",
                    "        np.sqrt(mean_squared_error(y_test, lr_pred)),\n",
                    "        np.sqrt(mean_squared_error(y_test, rf_pred)),\n",
                    "        np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
                    "    ]\n",
                    "})\n",
                    "\n",
                    "results"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 2. Long-Short Portfolio Backtest"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "def create_long_short_portfolio(df, percentile=30):\n",
                    "    \"\"\"Create long-short portfolio based on ESG scores\"\"\"\n",
                    "    # Sort by ESG score\n",
                    "    df_sorted = df.sort_values('totalEsg', ascending=False)\n",
                    "    \n",
                    "    # Calculate cutoff points\n",
                    "    n_stocks = len(df_sorted)\n",
                    "    top_n = int(n_stocks * (percentile/100))\n",
                    "    \n",
                    "    # Create portfolios\n",
                    "    long_portfolio = df_sorted.head(top_n)\n",
                    "    short_portfolio = df_sorted.tail(top_n)\n",
                    "    \n",
                    "    # Calculate portfolio returns\n",
                    "    return_periods = ['1M_Return', '3M_Return', '6M_Return', '12M_Return']\n",
                    "    portfolio_returns = pd.DataFrame()\n",
                    "    \n",
                    "    for period in return_periods:\n",
                    "        long_return = long_portfolio[period].mean()\n",
                    "        short_return = short_portfolio[period].mean()\n",
                    "        ls_return = long_return - short_return\n",
                    "        \n",
                    "        portfolio_returns[period] = [ls_return]\n",
                    "    \n",
                    "    return portfolio_returns, long_portfolio, short_portfolio\n",
                    "\n",
                    "# Create portfolios\n",
                    "portfolio_returns, long_portfolio, short_portfolio = create_long_short_portfolio(df)\n",
                    "\n",
                    "# Calculate performance metrics\n",
                    "def calculate_portfolio_metrics(returns):\n",
                    "    \"\"\"Calculate portfolio performance metrics\"\"\"\n",
                    "    metrics = pd.DataFrame()\n",
                    "    \n",
                    "    for col in returns.columns:\n",
                    "        ret = returns[col].iloc[0]\n",
                    "        metrics[col] = [\n",
                    "            ret,  # Return\n",
                    "            ret / returns[col].std()  # Sharpe (simplified)\n",
                    "        ]\n",
                    "    \n",
                    "    metrics.index = ['Return', 'Sharpe Ratio']\n",
                    "    return metrics\n",
                    "\n",
                    "portfolio_metrics = calculate_portfolio_metrics(portfolio_returns)\n",
                    "portfolio_metrics"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 3. Sector-Level Signal Detection"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "def analyze_sector_signals(df, return_period='12M_Return'):\n",
                    "    \"\"\"Analyze ESG signal strength by sector\"\"\"\n",
                    "    sectors = df['GIS Sector'].unique()\n",
                    "    sector_results = []\n",
                    "    \n",
                    "    for sector in sectors:\n",
                    "        sector_data = df[df['GIS Sector'] == sector]\n",
                    "        \n",
                    "        # Simple regression for each sector\n",
                    "        X = sector_data['totalEsg'].values.reshape(-1, 1)\n",
                    "        y = sector_data[return_period].values\n",
                    "        \n",
                    "        model = LinearRegression()\n",
                    "        model.fit(X, y)\n",
                    "        \n",
                    "        sector_results.append({\n",
                    "            'Sector': sector,\n",
                    "            'R2': r2_score(y, model.predict(X)),\n",
                    "            'Coefficient': model.coef_[0],\n",
                    "            'N_Stocks': len(sector_data)\n",
                    "        })\n",
                    "    \n",
                    "    return pd.DataFrame(sector_results)\n",
                    "\n",
                    "sector_analysis = analyze_sector_signals(df)\n",
                    "sector_analysis.sort_values('R2', ascending=False)"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 4. Clustering Analysis"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "def perform_clustering(df, n_clusters=5):\n",
                    "    \"\"\"Perform clustering analysis\"\"\"\n",
                    "    # Select features for clustering\n",
                    "    features = ['totalEsg', '12M_Return', 'environmentScore', 'socialScore', 'governanceScore']\n",
                    "    X = df[features]\n",
                    "    \n",
                    "    # Scale features\n",
                    "    scaler = StandardScaler()\n",
                    "    X_scaled = scaler.fit_transform(X)\n",
                    "    \n",
                    "    # Perform clustering\n",
                    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
                    "    clusters = kmeans.fit_predict(X_scaled)\n",
                    "    \n",
                    "    # Add cluster labels to data\n",
                    "    df_clustered = df.copy()\n",
                    "    df_clustered['Cluster'] = clusters\n",
                    "    \n",
                    "    # Calculate cluster characteristics\n",
                    "    cluster_stats = df_clustered.groupby('Cluster').agg({\n",
                    "        'totalEsg': 'mean',\n",
                    "        '12M_Return': 'mean',\n",
                    "        'environmentScore': 'mean',\n",
                    "        'socialScore': 'mean',\n",
                    "        'governanceScore': 'mean'\n",
                    "    }).round(4)\n",
                    "    \n",
                    "    return df_clustered, cluster_stats\n",
                    "\n",
                    "# Perform clustering\n",
                    "df_clustered, cluster_stats = perform_clustering(df)\n",
                    "\n",
                    "# Create visualization\n",
                    "fig = px.scatter(df_clustered, \n",
                    "                 x='totalEsg', \n",
                    "                 y='12M_Return',\n",
                    "                 color='Cluster',\n",
                    "                 hover_data=['Ticker', 'GIS Sector'],\n",
                    "                 title='Stock Clusters based on ESG and Returns')\n",
                    "\n",
                    "fig.show()\n",
                    "cluster_stats"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 1. Feature Importance Analysis"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "# Prepare data with individual ESG components\n",
                    "def prepare_detailed_data(df, target_col='12M_Return'):\n",
                    "    X = df[['environmentScore', 'socialScore', 'governanceScore', 'GIS Sector']]\n",
                    "    y = df[target_col]\n",
                    "    \n",
                    "    preprocessor = ColumnTransformer(\n",
                    "        transformers=[\n",
                    "            ('num', StandardScaler(), ['environmentScore', 'socialScore', 'governanceScore']),\n",
                    "            ('cat', OneHotEncoder(drop='first', sparse_output=False), ['GIS Sector'])\n",
                    "        ])\n",
                    "    \n",
                    "    return train_test_split(X, y, test_size=0.2, random_state=42), preprocessor\n",
                    "\n",
                    "# Train Random Forest with individual components\n",
                    "(X_train, X_test, y_train, y_test), preprocessor = prepare_detailed_data(df)\n",
                    "\n",
                    "rf_detailed = Pipeline([\n",
                    "    ('preprocessor', preprocessor),\n",
                    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
                    "])\n",
                    "\n",
                    "rf_detailed.fit(X_train, y_train)\n",
                    "\n",
                    "# Get feature names after preprocessing\n",
                    "feature_names = (\n",
                    "    ['environmentScore', 'socialScore', 'governanceScore'] +\n",
                    "    [f'Sector_{sector}' for sector in preprocessor.named_transformers_['cat'].get_feature_names_out(['GIS Sector'])]\n",
                    ")\n",
                    "\n",
                    "# Extract feature importance\n",
                    "importances = rf_detailed.named_steps['regressor'].feature_importances_\n",
                    "importance_df = pd.DataFrame({\n",
                    "    'Feature': feature_names,\n",
                    "    'Importance': importances\n",
                    "}).sort_values('Importance', ascending=False)\n",
                    "\n",
                    "# Plot feature importance\n",
                    "plt.figure(figsize=(12, 6))\n",
                    "sns.barplot(data=importance_df.head(10), x='Importance', y='Feature')\n",
                    "plt.title('Top 10 Most Important Features for Return Prediction')\n",
                    "plt.tight_layout()\n",
                    "plt.show()"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 2. ESG Component Analysis"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "# Create correlation matrix\n",
                    "esg_cols = ['environmentScore', 'socialScore', 'governanceScore', '12M_Return']\n",
                    "corr_matrix = df[esg_cols].corr()\n",
                    "\n",
                    "plt.figure(figsize=(10, 8))\n",
                    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
                    "plt.title('Correlation between ESG Components and Returns')\n",
                    "plt.tight_layout()\n",
                    "plt.show()\n",
                    "\n",
                    "# Create scatter plots\n",
                    "fig = make_subplots(rows=1, cols=3,\n",
                    "                    subplot_titles=('Environmental Score vs Returns',\n",
                    "                                   'Social Score vs Returns',\n",
                    "                                   'Governance Score vs Returns'))\n",
                    "\n",
                    "for i, score in enumerate(['environmentScore', 'socialScore', 'governanceScore']):\n",
                    "    fig.add_trace(\n",
                    "        go.Scatter(x=df[score], y=df['12M_Return'],\n",
                    "                   mode='markers',\n",
                    "                   name=score.replace('Score', ''),\n",
                    "                   marker=dict(color=df['GIS Sector'].astype('category').cat.codes,\n",
                    "                              colorscale='Viridis',\n",
                    "                              showscale=True if i == 2 else False),\n",
                    "                   text=df['GIS Sector']),\n",
                    "        row=1, col=i+1\n",
                    "    )\n",
                    "\n",
                    "fig.update_layout(height=400, width=1200, title_text='ESG Components vs 12-Month Returns')\n",
                    "fig.show()"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 3. Energy Sector Deep Dive"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "# Filter Energy sector data\n",
                    "energy_df = df[df['GIS Sector'] == 'Energy'].copy()\n",
                    "\n",
                    "# Create prediction model for Energy sector\n",
                    "X_energy = energy_df[['environmentScore', 'socialScore', 'governanceScore']]\n",
                    "y_energy = energy_df['12M_Return']\n",
                    "\n",
                    "# Scale features\n",
                    "scaler = StandardScaler()\n",
                    "X_energy_scaled = scaler.fit_transform(X_energy)\n",
                    "\n",
                    "# Train models\n",
                    "models = {\n",
                    "    'Linear Regression': LinearRegression(),\n",
                    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
                    "    'XGBoost': xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
                    "}\n",
                    "\n",
                    "# Cross-validation results\n",
                    "cv_results = {}\n",
                    "for name, model in models.items():\n",
                    "    scores = cross_val_score(model, X_energy_scaled, y_energy, cv=3, scoring='r2')\n",
                    "    cv_results[name] = {\n",
                    "        'Mean R2': scores.mean(),\n",
                    "        'Std R2': scores.std()\n",
                    "    }\n",
                    "\n",
                    "# Display results\n",
                    "pd.DataFrame(cv_results).T"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 4. ESG Score Distribution by Sector"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "# Create violin plots for ESG components by sector\n",
                    "fig = make_subplots(rows=3, cols=1,\n",
                    "                    subplot_titles=('Environmental Scores by Sector',\n",
                    "                                   'Social Scores by Sector',\n",
                    "                                   'Governance Scores by Sector'),\n",
                    "                    vertical_spacing=0.1)\n",
                    "\n",
                    "for i, score in enumerate(['environmentScore', 'socialScore', 'governanceScore']):\n",
                    "    fig.add_trace(\n",
                    "        go.Violin(x=df['GIS Sector'], y=df[score],\n",
                    "                  name=score.replace('Score', ''),\n",
                    "                  box_visible=True,\n",
                    "                  meanline_visible=True),\n",
                    "        row=i+1, col=1\n",
                    "    )\n",
                    "\n",
                    "fig.update_layout(height=1200, width=1000,\n",
                    "                  title_text='Distribution of ESG Components by Sector',\n",
                    "                  showlegend=False)\n",
                    "fig.show()"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## 5. Return Distribution Analysis"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "outputs": [],
                "source": [
                    "# Create quartiles for each ESG component\n",
                    "for score in ['environmentScore', 'socialScore', 'governanceScore']:\n",
                    "    df[f'{score}_quartile'] = pd.qcut(df[score], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
                    "\n",
                    "# Plot return distributions by ESG quartiles\n",
                    "fig = make_subplots(rows=1, cols=3,\n",
                    "                    subplot_titles=('Returns by Environmental Quartile',\n",
                    "                                   'Returns by Social Quartile',\n",
                    "                                   'Returns by Governance Quartile'))\n",
                    "\n",
                    "for i, score in enumerate(['environmentScore', 'socialScore', 'governanceScore']):\n",
                    "    fig.add_trace(\n",
                    "        go.Box(x=df[f'{score}_quartile'], y=df['12M_Return'],\n",
                    "               name=score.replace('Score', '')),\n",
                    "        row=1, col=i+1\n",
                    "    )\n",
                    "\n",
                    "fig.update_layout(height=400, width=1200,\n",
                    "                  title_text='Return Distributions by ESG Component Quartiles')\n",
                    "fig.show()"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "## Summary of Findings\n",
                    "\n",
                    "1. **Feature Importance**\n",
                    "   - Ranking of most influential factors\n",
                    "   - Sector-specific impacts\n",
                    "   - Individual ESG component weights\n",
                    "\n",
                    "2. **ESG Components**\n",
                    "   - Correlation patterns\n",
                    "   - Component-specific return relationships\n",
                    "   - Sector variations\n",
                    "\n",
                    "3. **Energy Sector Analysis**\n",
                    "   - Model performance\n",
                    "   - Predictive power\n",
                    "   - Key drivers\n",
                    "\n",
                    "4. **Sector Patterns**\n",
                    "   - ESG score distributions\n",
                    "   - Sector-specific characteristics\n",
                    "   - Return patterns\n",
                    "\n",
                    "5. **Return Distribution**\n",
                    "   - Quartile analysis\n",
                    "   - Risk-return patterns\n",
                    "   - Component-specific effects"
                ]
            }
        ],
        "metadata": {
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python",
                "name": "python3"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 4
    }

    # Save the notebook
    with open('ESG_Portfolio_Modeling.ipynb', 'w') as f:
        json.dump(notebook, f, indent=1)

if __name__ == "__main__":
    create_notebook() 